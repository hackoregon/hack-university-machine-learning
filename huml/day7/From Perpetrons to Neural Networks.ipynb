{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Neural Networks\n",
    "## Part 1: Perceptrons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Neural Networks? Why Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent developments in neural networks have \"created\" these art works.\n",
    "![A Neural Algorithm of Artistic Style, Leon A. Gatys, Alexander S. Ecker, Matthias Bethge](https://thestack.com/wp-content/uploads/2015/09/starry-night.jpg)\n",
    "taken from a paper on [A Neural Algorithm of Artistic Style by Leon A. Gatys, Alexander S. Ecker, Matthias Bethge](http://arxiv.org/pdf/1508.06576.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Consider a single neuron cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A Neuron](https://upload.wikimedia.org/wikipedia/commons/b/bd/Neuron.jpg)\n",
    "Source: [Wikipedia](https://upload.wikimedia.org/wikipedia/commons/b/bd/Neuron.jpg)\n",
    "\n",
    "If the stimulus to a neuron cell is above a \"threshold\", the cell is activated and will release a tiny electrical impulse to the next cells which it is connected with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How could this be represented mathematically?\n",
    "![Structure of a single perceptron](https://upload.wikimedia.org/wikipedia/commons/8/8c/Perceptron_moj.png)\n",
    "Source: [Wikipedia](https://upload.wikimedia.org/wikipedia/commons/8/8c/Perceptron_moj.png)\n",
    "\n",
    "$$ f(x) = \\begin{cases}1 & \\text{if }\\vec{x} \\cdot \\vec{w} + w_0 > 0\\\\0 & \\text{otherwise}\\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Representation of a Single Layer Perceptron\n",
    "\n",
    "$$ w = \\begin{bmatrix}\n",
    "         w_1 \\\\\n",
    "         \\vdots \\\\\n",
    "         w_n\n",
    "        \\end{bmatrix} \n",
    "   x = \\begin{bmatrix}\n",
    "         x_1 \\\\\n",
    "         \\vdots \\\\\n",
    "         x_n\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Linear Activation Function\n",
    "\n",
    "\\begin{equation*}\n",
    "z = x^T * w + w_0\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\phi(z) = \\begin{cases}\n",
    "1\\ if\\ z > 0 \\\\\n",
    "0\\ otherwise\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "#### How does the single layer perceptron learn?\n",
    "\n",
    "1. Initialize the weights with zero values\n",
    "2. For each training sample, compute the predicted $y$ and update the weights accordingly\n",
    "\n",
    "\\begin{equation*} \n",
    "\\Delta w = \\eta(y_{training set}^{(i)} - y_{predicted}^{(i)}) x^{(i)} \\\\\n",
    "w = w + \\Delta w \\\\\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install all required packages with 'pip install -r requirements.txt'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"\n",
    "    \n",
    "    Perceptron classifier.\n",
    "\n",
    "    Adopted from Python Machine Learning by Sebastian Raschka (see below)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, epoches=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoches = epoches\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"This method will fit the perceptron activation function to match the training set\"\"\"\n",
    "        \n",
    "        # set self.weights to a zero value\n",
    "        # check out a numpy method, get the dimension of the input vector X \n",
    "        # with `X.shape[1]`\n",
    "    \n",
    "        self.weights = numpy.zeros(1 + X.shape[1])\n",
    "        self.errors = []\n",
    "\n",
    "        for _ in range(self.epoches):\n",
    "            errors = 0\n",
    "            for xi, expected_y in zip(X, y):\n",
    "                update = ... # update the update rule\n",
    "                self.weights[1:] += # update the weights for x[1:n]\n",
    "                self.weights[0] += # update the weight x[0]\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors.append(errors)\n",
    "        return self    \n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"This method will calculate the dot product of the input vector x multiplied with the vector of the weights.\n",
    "           Don't forget the bias w_0\n",
    "        \"\"\"\n",
    "        ### TASK: Calculate this sum of the multipled vectors x and w. You can either do this by using the numpy.dot\n",
    "        ### method or by using a for loop (the numpy.dot method will be faster but less intuitive)\n",
    "        return ...\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        ### TASK: Take a result from self.net_input(X) and classify it. \n",
    "        ### Return 1 if the result is greater than 0, other return 1\n",
    "        return ...\n",
    "      \n",
    "    def feature_scaling(self, X):\n",
    "        \"\"\" Scales features between 0 and 1 \"\"\"\n",
    "        # perform feature scaling on each column\n",
    "        for col in list(X.columns.values):\n",
    "            X[col] = X[col] / X[col].max()\n",
    "        return X\n",
    "        \n",
    "    def plot(self, X, y, \n",
    "             cols=[0, 1], \n",
    "             axis_labels=['x', 'y'], \n",
    "             _max_samples=100,\n",
    "             save=False\n",
    "            ):\n",
    "        max_samples = _max_samples if _max_samples < len(y) else len(y)\n",
    "        X = X[0:max_samples, cols]\n",
    "        for i in range(0, max_samples):\n",
    "            if int(y[i]) == 1:\n",
    "                color='red'\n",
    "                marker='o'\n",
    "            else:\n",
    "                color='blue'\n",
    "                marker='x'\n",
    "            plt.scatter(\n",
    "                X[i][cols[0]], X[i][cols[1]],\n",
    "                color=color, marker=marker, )\n",
    "\n",
    "        plt.xlabel(axis_labels[0])\n",
    "        plt.ylabel(axis_labels[1])\n",
    "        plt.show()\n",
    " \n",
    "    def plot_errors(self):\n",
    "        plt.plot(range(1, len(p.errors) + 1), p.errors, marker='o')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Number of misclassifications')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def cross_val_score(self, X, y):\n",
    "        \"\"\"Returns the CV matrix for a model and its expected results\"\"\"\n",
    "        # set variables\n",
    "        _pred_y = self.predict(X)\n",
    "        cov_results = numpy.zeros((2,2))\n",
    "        # Check for positives and negatives\n",
    "        positions = (\n",
    "            list(numpy.where(y != 1))[0],\n",
    "            list(numpy.where(y == 1))[0]\n",
    "        )\n",
    "        for res in [0, 1]:\n",
    "            # get total number of pos/neg samples\n",
    "            total = len(positions[res])\n",
    "            # loop through sample positions\n",
    "            for pos in list(positions[res]):\n",
    "                # check postives\n",
    "                if y[pos] == 1:\n",
    "                    if _pred_y[pos] == 1:\n",
    "                        cov_results[1, 1] += 1\n",
    "                    else:\n",
    "                        cov_results[1, 0] += 1\n",
    "                # check not positives (could be -1 or 0)\n",
    "                else:\n",
    "                    if _pred_y[pos] != 1:\n",
    "                        cov_results[0, 0] += 1\n",
    "                    else:\n",
    "                        cov_results[0, 1] += 1\n",
    "            # divide results by the number of samples in the category (positive/negative)\n",
    "            cov_results[res, :] /= total\n",
    "        return cov_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR Examples, solved by a single Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OR example\n",
    "\n",
    "data_set = numpy.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "p = Perceptron(0.01, 10)\n",
    "p.fit(data_set[:, :2], data_set[:, 2:])\n",
    "print ('Prediction: ', p.predict(data_set[:, :2]))\n",
    "print ('Cross validation: ')\n",
    "print p.cross_val_score(data_set[:, :2], data_set[:, 2:])\n",
    "p.plot(data_set[:, :2], data_set[:, 2])\n",
    "p.predict(data_set[:, :2])\n",
    "p.plot_errors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset\n",
    "Determine the type of Irises (in this case, we classify between setosa and versicolor). The classic data originates from the [UCI dataset server](http://archive.ics.uci.edu/ml/) and is one of the most downloaded sets so far. An overview of the different input variables can be found [here](https://en.wikipedia.org/wiki/Iris_flower_data_set#/media/File:Iris_dataset_scatterplot.svg).\n",
    "For this tutorial, let's classify the Irises by the sepal and petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "        'machine-learning-databases/iris/iris.data', header=None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# select setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = numpy.where(y == 'Iris-setosa', 0, 1)\n",
    "\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100, [0, 2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Perceptron(learning_rate=0.1, epoches=10)\n",
    "\n",
    "p.fit(X, y)\n",
    "p.plot(X, y)\n",
    "p.plot_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.cross_val_score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y\n",
    "print p.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit card fraud dectection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://onlinecourses.science.psu.edu/stat857/node/215\n",
    "import pandas as pd\n",
    "\n",
    "training_set = pd.read_csv('german_credit_dataset/Training50.csv')\n",
    "test_set = pd.read_csv('german_credit_dataset/Test50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop id column from training/test set\n",
    "training_set.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# inspect dataset\n",
    "print training_set.columns\n",
    "# training_set.head()\n",
    "training_set.head()  # training_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform feature scaling on each column\n",
    "for col in list(training_set.columns.values):\n",
    "    training_set[col] = training_set[col] / training_set[col].max()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the creditability column as y vector\n",
    "y = training_set['Creditability'].values\n",
    "# drop the creditability column from the dataset\n",
    "training_set.drop('Creditability', axis=1, inplace=True)\n",
    "# remaining dataset is used as input matrix\n",
    "X = training_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Perceptron(0.0001, 1000)\n",
    "p.fit(X, y)\n",
    "p.predict(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p.cross_val_score(X, y)\n",
    "p.plot(training_set[['Account.Balance', 'Purpose']].values, y)\n",
    "p.plot_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Try the XOR Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XOR problem\n",
    "\n",
    "data_set = numpy.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "p = Perceptron(0.01, 10)\n",
    "p.fit(data_set[:, :2], data_set[:, 2])\n",
    "print ('Prediction: ', p.predict(data_set[:, :2]))\n",
    "print ('Cross validation: ')\n",
    "print p.cross_val_score(data_set[:, :2], data_set[:, 2])\n",
    "p.plot(data_set[:, :2], data_set[:, 2], axis_labels=['x1', 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XOR problem solved with a single layer perceptron\n",
    "\n",
    "data_set = numpy.array([\n",
    "    # index, (x1+x2)^2, output\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 1],\n",
    "    [2, 1, 1],\n",
    "    [3, 4, 0]\n",
    "])\n",
    "\n",
    "p = Perceptron(0.001, 1000)\n",
    "p.fit(data_set[:, :2], data_set[:, 2])\n",
    "print ('Prediction: ', p.predict(data_set[:, :2]))\n",
    "print ('Cross validation: ')\n",
    "print p.cross_val_score(data_set[:, :2], data_set[:, 2])\n",
    "p.plot(data_set[:, [0,1]], data_set[:, 2], axis_labels=['x1', 'x2'])\n",
    "p.predict([3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why isn't the perceptron working for the XOR example?\n",
    "### What needs to be adapted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
